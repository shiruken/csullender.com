<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Coding on Colin Sullender</title><link>https://csullender.com/tags/coding/</link><description>Recent content in Coding on Colin Sullender</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 30 Apr 2024 12:44:20 -0600</lastBuildDate><atom:link href="https://csullender.com/tags/coding/index.xml" rel="self" type="application/rss+xml"/><item><title>Tracking Broken Water Pipes in Austin, TX</title><link>https://csullender.com/posts/tracking-broken-water-pipes/</link><pubDate>Mon, 08 Mar 2021 15:00:00 -0500</pubDate><guid>https://csullender.com/posts/tracking-broken-water-pipes/</guid><description>&lt;p>A massive winter storm in February &lt;a href="https://www.nytimes.com/interactive/2021/02/19/climate/texas-storm-power-generation-charts.html" class="external-link" target="_blank" rel="noopener">disrupted power generation across the state of Texas&lt;/a> and caused &lt;a href="https://www.texastribune.org/2021/02/17/texas-winter-storm-power-outage-ercot/" class="external-link" target="_blank" rel="noopener">nearly 3 million households to lose electricity&lt;/a>. As Austin Energy &lt;a href="https://www.statesman.com/story/weather/2021/02/15/austin-energy-begins-rolling-outages-across-city-ease-strain-power-grid/4487244001/" class="external-link" target="_blank" rel="noopener">struggled to implement rolling blackouts&lt;/a> to reduce energy demand, many neighborhoods in the city went multiple days without electricity during &lt;a href="https://www.kxan.com/weather/weather-blog/cold-wave-surpasses-83-arctic-outbreak-enters-record-books/" class="external-link" target="_blank" rel="noopener">record-breaking cold weather&lt;/a>. With residents suddenly unable to heat their homes, Austin and Travis County emergency services &lt;a href="https://www.statesman.com/story/news/2021/02/15/winter-storm-texas-hundreds-austin-report-broken-water-pipes-request-medical-services/6760606002/" class="external-link" target="_blank" rel="noopener">were flooded with calls about broken water pipes&lt;/a>. By late afternoon on February 15th, the Austin Fire Department&amp;rsquo;s &lt;a href="https://www.austintexas.gov/fact/default.cfm" class="external-link" target="_blank" rel="noopener">Active Fire Incidents&lt;/a> page was filled with dozens of &amp;ldquo;BWP - Broken Water Pipe&amp;rdquo; incident reports.&lt;/p></description></item><item><title>Google Scholar Visualization</title><link>https://csullender.com/posts/google-scholar-visualization/</link><pubDate>Sun, 08 Feb 2015 16:59:45 +0000</pubDate><guid>https://csullender.com/posts/google-scholar-visualization/</guid><description>&lt;p>One of the most common images I see during science presentations is the frequency of publications within a particular field over time. It&amp;rsquo;s a great way to show the growth of the field while attempting to validate the worthiness of the research that follows. As far as I can tell, most people manually assemble this data with sequential searches on &lt;a href="https://scholar.google.com/" class="external-link" target="_blank" rel="noopener">Google Scholar&lt;/a> or &lt;a href="https://webofknowledge.com/" class="external-link" target="_blank" rel="noopener">Web of Science&lt;/a>. This seemed like a straightforward opportunity for automation, so &lt;del>I made a little website&lt;/del> (&lt;em>Deprecated July 2022&lt;/em>) that does just that. It takes a Google Scholar search query and a range of years and plots the number of results over time.&lt;/p></description></item><item><title>Taylor Swifting</title><link>https://csullender.com/posts/taylor-swifting/</link><pubDate>Sun, 30 Nov 2014 06:28:36 +0000</pubDate><guid>https://csullender.com/posts/taylor-swifting/</guid><description>&lt;p>I had a &lt;a href="https://twitter.com/shiruken/status/536957959503241217" class="external-link" target="_blank" rel="noopener">really random idea&lt;/a> the other day for a simple coding project using the LastFM API: When was the last time you listened to Taylor Swift? This is obviously an extremely important statistic to know for the Taylor Swift obsessed. I already made a tool to &lt;a href="https://csullender.com/first" >&lt;del>lookup the first time you listened to an artist&lt;/del>&lt;/a> using your LastFM profile, so this was a relatively straightforward adaptation. I also wanted to take this opportunity to leverage the power of &lt;a href="http://jquery.com/" class="external-link" target="_blank" rel="noopener">jQuery&lt;/a> to asynchronously load the information rather than simply waiting for a static page. Check out &lt;del>The Last Swifting page&lt;/del> (&lt;em>Deprecated July 2022&lt;/em>) or continue reading for more information.&lt;/p></description></item><item><title>Dogecoin Halving Countdown</title><link>https://csullender.com/posts/dogecoin-halving-countdown/</link><pubDate>Thu, 20 Feb 2014 02:07:32 +0000</pubDate><guid>https://csullender.com/posts/dogecoin-halving-countdown/</guid><description>&lt;p>The first block reward halving for &lt;a href="http://dogecoin.com/" class="external-link" target="_blank" rel="noopener">Dogecoin&lt;/a> resulted in many &lt;a href="http://www.reddit.com/r/dogecoin/" class="external-link" target="_blank" rel="noopener">Reddit users&lt;/a> asking when the event was occurring and how much the new block reward would be. I haven&amp;rsquo;t been able to find a good countdown website so I decided to throw one together myself. It uses the &lt;a href="http://dogechain.info/chain/Dogecoin" class="external-link" target="_blank" rel="noopener">DogeChain&lt;/a> API to grab the current block number and estimates the time until the next change in the block reward. Since the Dogecoin &lt;a href="https://bitcointalk.org/index.php?PHPSESSID=7fsbe1l362dulhpb5an0j4imq0&amp;amp;topic=361813.msg3872945#msg3872945" class="external-link" target="_blank" rel="noopener">protocol&lt;/a> establishes the specific block rewards, it&amp;rsquo;s relatively simple to calculate it with some accuracy. Check it out by &lt;del>clicking here&lt;/del> &lt;em>(Deprecated July 2022)&lt;/em>.&lt;/p></description></item><item><title>Foursquare Heatmap</title><link>https://csullender.com/posts/foursquare-heatmap/</link><pubDate>Fri, 27 Dec 2013 23:06:19 +0000</pubDate><guid>https://csullender.com/posts/foursquare-heatmap/</guid><description>&lt;p>I&amp;rsquo;m a regular user of the location-based social network &lt;a href="https://foursquare.com/" class="external-link" target="_blank" rel="noopener">Foursquare&lt;/a> mainly as a source of recommendations for new places to try. I typically check in everywhere I go with the exception of private residences (can&amp;rsquo;t let people stalk me that easily), so I have a pretty extensive log covering my location history. While it&amp;rsquo;s not quite as extensive as the &lt;a href="https://maps.google.com/locationhistory/b/0" class="external-link" target="_blank" rel="noopener">Google Maps Location History&lt;/a>, it does a good job representing the places I visit.&lt;/p></description></item><item><title>LastFM First Listen</title><link>https://csullender.com/posts/lastfm-first-listen/</link><pubDate>Tue, 26 Mar 2013 03:55:01 +0000</pubDate><guid>https://csullender.com/posts/lastfm-first-listen/</guid><description>&lt;p>When was the first time you listened to M83? What about LIGHTS? If you&amp;rsquo;re a &lt;a href="http://www.last.fm/" class="external-link" target="_blank" rel="noopener">LastFM&lt;/a> user, then I&amp;rsquo;ve made a &lt;del>little web-app&lt;/del> (&lt;em>Deprecated July 2022&lt;/em>) you can use to look it up! All you need is an active LastFM account and to have been tracking your music listening with their scrobbling service.&lt;/p>
&lt;p>&lt;img src="M83First.jpg" alt="First Time I Listened to M83">&lt;/p>
&lt;p>All you need to do is enter any LastFM username and artist and then hit submit. The website uses the LastFM &lt;code>user.getArtistTracks&lt;/code> API method to fetch every single track the user has scrobbled from that particular artist. The XML returned file is segmented into 50 plays-per-page but fortunately reports the total number of pages in the first child element. This number is used to jump to the last page of the data, which contains the very first scrobbled track by the user for the particular artist. From there it&amp;rsquo;s just a matter of parsing the XML structure and grabbing the necessary information for display on the webpage with PHP.&lt;/p></description></item><item><title>Twitter Analytics 2.0</title><link>https://csullender.com/posts/twitter-analytics-2-0/</link><pubDate>Sun, 03 Feb 2013 22:07:44 +0000</pubDate><guid>https://csullender.com/posts/twitter-analytics-2-0/</guid><description>&lt;p>A couple years ago I made a simple Twitter Stats page to depict my tweeting activity. It was originally powered by some datasets pulled from &lt;a href="http://www.tweetstats.com/" title="Visit Tweetstats" class="external-link" target="_blank" rel="noopener">TweetStats&lt;/a> but I eventually upgraded it to run entirely from my own server. It was extremely barebones and grabbed my &lt;a href="https://twitter.com/shiruken" title="View My Twitter" class="external-link" target="_blank" rel="noopener">Twitter&lt;/a> feed every hour and downloaded all the tweets that had been added since the previous update. Unfortunately, because Twitter does not offer the entire tweeting history via the website or this XML feed, I was missing well over a year of data. Combined with problems accessing this feed, I would regularly lose my entire (local) cache of my Twitter feed and have to spend a lot of time fixing everything. I eventually just decided to kill off the page since I was losing more and more of the older tweets every time I had to fix the cache and Twitter was changing the way the feed was presented.&lt;/p></description></item></channel></rss>